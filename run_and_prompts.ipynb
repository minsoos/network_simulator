{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Network and relations making"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import os\n",
                "import time\n",
                "from yml_create_functions import make_yml, make_network_agents_yml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "name_simulation = 'simulation_tutorial'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Network Agent Parameters"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The schema can be changed in schema/schema.py. Here, you can change the parameters of the default schema"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "network_agents_parameters = {\n",
                "    \"default\": {\n",
                "        \"id_message\": \"NaN\",\n",
                "        \"has_tv\": \"false\",\n",
                "        \"cause\": -1,\n",
                "        \"method\": \"NaN\",\n",
                "\n",
                "        \"type\": \"dumb\",\n",
                "        \"response\": \"NaN\",\n",
                "        \"stance\": \"agree\",\n",
                "        \"repost\": \"NaN\",\n",
                "        \"parent_id\": \"NaN\"\n",
                "\n",
                "    },\n",
                "\n",
                "    \"DumbViewer\": [\n",
                "        {\"weight\": 2, \"type\": \"dumb\"},\n",
                "        {\"weight\": 2, \"type\": \"dumb\", \"has_tv\": \"true\"}\n",
                "    ],\n",
                "    \"HerdViewer\": [\n",
                "        {\"weight\": 2, \"type\": \"herd\", \"stance\": \"against\"},\n",
                "        {\"weight\": 2, \"type\": \"herd\", \"has_tv\": \"true\"}\n",
                "    ],\n",
                "    \"WiseViewer\": [\n",
                "        {\"weight\": 1, \"type\": \"wise\", \"stance\": \"against\"},\n",
                "        {\"weight\": 1, \"type\": \"wise\", \"has_tv\": \"true\", \"stance\": \"neutral\"}\n",
                "    ],\n",
                "\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Other Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "INTERVALS = 100\n",
                "parameters = {\n",
                "    \"default_state\": \"{}\",\n",
                "    \"load_module\": \"schema\", # path from yml to schema\n",
                "    \"environment_agents\": \"[]\",\n",
                "    \"environment_class\": \"schema.NewsEnvironmentAgent\", # path from yml to environment class\n",
                "    \"environment_params\": {\n",
                "        \"prob_neighbor_spread\": 0.05,  # 006\n",
                "        \"prob_tv_spread\": 0.05,  # 001\n",
                "        \"prob_neighbor_cure\": 0.006,  # 001\n",
                "        \"prob_backsliding\": 0.01,  # 003\n",
                "        \"prob_dead\": 0.001,  # 001,\n",
                "        \"prob_repost\": 0.8,\n",
                "        \"mean_time_connection\": 10,\n",
                "        \"var_time_connection\": 30\n",
                "    },\n",
                "    \"interval\": 1,\n",
                "    \"max_time\": INTERVALS,\n",
                "    \"name\": name_simulation,\n",
                "    \"network_params\": {\n",
                "        \"generator\": \"barabasi_albert_graph\",\n",
                "        \"n\": 200,\n",
                "        \"m\": 5\n",
                "    },\n",
                "    \"num_trials\": 1\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Prob responses parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define your probabilities here\n",
                "prob_response = {\"dumb\": {\"support\": 0.4, \"deny\": 0.3, \"question\": 0, \"comment\": 0.2},\n",
                "                \"herd\": {\"support\": 0.25, \"deny\": 0.25, \"question\": 0.25, \"comment\": 0.25},\n",
                "                \"wise\": {\"support\": 0.2, \"deny\": 0.2, \"question\": 0.3, \"comment\": 0.3}\n",
                "                }\n",
                "types = list(prob_response.keys())\n",
                "responses = list( prob_response[types[0]].keys() )\n",
                "for type_i in types:\n",
                "    for response in responses:\n",
                "        name_i = f\"prob_{type_i}_{response}\"\n",
                "        prob_i = prob_response[type_i][response]\n",
                "        # Here, we set each probability\n",
                "        parameters[\"environment_params\"][name_i] = prob_i"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Simulation execution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SIMULATION'S SECONDS: 10.643027067184448\n"
                    ]
                }
            ],
            "source": [
                "parameters_i = parameters.copy()\n",
                "network_agents_parameters_i = network_agents_parameters.copy()\n",
                "data = make_yml(parameters_i)\n",
                "data += make_network_agents_yml(network_agents_parameters_i)\n",
                "\n",
                "yml_path = os.path.join('schema', f'{name_simulation}.yml') # YML path\n",
                "with open(yml_path, 'w') as file:\n",
                "    file.write(data)\n",
                "\n",
                "command = \"soil\"\n",
                "start = time.time()\n",
                "\n",
                "output = subprocess.check_output([command, yml_path])\n",
                "end = time.time()\n",
                "seconds_simulation = str(end-start)\n",
                "print(\"SIMULATION'S SECONDS:\", seconds_simulation)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conversation Making"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "from get_data.get_data import get_pivoted_data, get_type_agents\n",
                "from post.templates import POST_TEMPLATE, REPLY_TEMPLATE, INSTRUCTIONS_TEMPLATE\n",
                "from post.transform_time import transform_time\n",
                "from spelling_checker.spelling_checker import correctness_prompt, correctness_percentage\n",
                "from anytree import Node, RenderTree, LevelOrderIter\n",
                "from post.post import Post\n",
                "from IA.gpt3_5 import send_prompt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Output sqlite path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "analysis_path = os.path.join('soil_output', name_simulation)\n",
                "sql_table_path = f'{name_simulation}_trial_0.sqlite'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "attributes = ['cause', 'method', 'response', 'stance', 'repost']\n",
                "\n",
                "data = get_pivoted_data(analysis_path, sql_table_path, attributes)\n",
                "dict_agents = get_type_agents(analysis_path, sql_table_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define News"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "NEWS = 'Dictan prisión preventiva para Pablo Mackenna tras protagonizar accidente de tránsito en estado de ebriedad en Las Condes. '\n",
                "NEWS_BODY = '''\n",
                "De acuerdo a los antecedentes que se manejan, Mackenna chocó un taxi ejecutivo en avenida Presidente Errázuriz con Calle Sánchez Fontecilla, provocando graves daños al otro vehículo y dejando una persona lesionada. Al practicarle la alcoholemia, arrojó 1,27 gramos de alcohol por litro de sangre. \"Nos tenemos que fijar en la conducta del imputado y en la forma en que pone en riesgo la vida de tercera personas, lo cual efectivamente pasó el día de hoy\", aseguró jueza Acevedo. Agregó que \"él chocó a un taxista, que el vehículo es su fuente de trabajo, por lo tanto, va a quedar sin poder trabajar, además de la licencia que tiene... También lesionó a otra persona\". Asimismo, enfatizó que Mackenna cruzó en luz roja, por lo que \"comete una infracción de tránsito, además del manejo en estado de ebriedad\". \"Se va a acceder a la solicitud de la Fiscalía, y se va a decretar la prisión preventiva\", señaló la jueza, precisando que se determinó un plazo de investigación de 90 días.\n",
                "'''\n",
                "SHOW_TREE = True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create the Network's Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "root = Post(0, message=NEWS, step=0, post_template=POST_TEMPLATE,\n",
                "             reply_template=REPLY_TEMPLATE,\n",
                "             instructions_template=INSTRUCTIONS_TEMPLATE, news=NEWS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 24 hours format\n",
                "TIME_BEG = \"10:00\"\n",
                "TIME_END = \"23:00\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "list_nodes = [root]\n",
                "num_real_messages = 0\n",
                "for i in range(len(data)):\n",
                "    aux = data[i]\n",
                "    owner = int(aux[0])\n",
                "    step = int(aux[1])\n",
                "    step = transform_time(step, TIME_BEG, TIME_END)\n",
                "    id_message = int(aux[2])\n",
                "    parent = list_nodes[int(aux[3])]\n",
                "    state = aux[4] #unused\n",
                "    attr_dict = {}\n",
                "    for index, attr in enumerate(attributes):\n",
                "        index +=5\n",
                "        attr_dict[attr] = aux[index] \n",
                "\n",
                "    type_agent = dict_agents[owner]\n",
                "    \n",
                "    ### Specific for repost attribute\n",
                "    if attr_dict[\"repost\"] in [\"0\", \"1\"]:\n",
                "        attr_dict[\"repost\"] = bool(int(attr_dict[\"repost\"]))\n",
                "    else:\n",
                "        print(data[i])\n",
                "        print(attr_dict[\"repost\"])\n",
                "        raise ValueError(\"Error repost format\")\n",
                "        \n",
                "    if not attr_dict[\"repost\"]:\n",
                "        num_real_messages += 1\n",
                "    ### \n",
                "\n",
                "    message = ''\n",
                "    news_i = NEWS\n",
                "    if type_agent == \"wise\":\n",
                "        news_i += NEWS_BODY\n",
                "\n",
                "    list_nodes.append(Post(name=id_message, parent=parent, owner=owner, step=step, message=message, type_agent=type_agent,\n",
                "                             post_template=POST_TEMPLATE, reply_template=REPLY_TEMPLATE,\n",
                "                             instructions_template=INSTRUCTIONS_TEMPLATE, news=news_i,\n",
                "                             **attr_dict\n",
                "                             )\n",
                "    )\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Associate a Written Post to each Message"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "from parameters import API_KEY\n",
                "import openai\n",
                "openai.api_key = API_KEY"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "TEMPERATURE = 1.0\n",
                "list_prompts = []\n",
                "i = 0\n",
                "num_llm_errors = 0\n",
                "MAX_LLM_ERRORS = 10\n",
                "for node_i in LevelOrderIter(root):\n",
                "    i += 1\n",
                "    if node_i == root:\n",
                "        continue\n",
                "    elif node_i.repost:\n",
                "        continue\n",
                "\n",
                "    instructions, prompt = node_i.get_prompt(language='english', \n",
                "                min_caract=130, max_caract=250,\n",
                "                user_description='average toxic and angry social media user')\n",
                "    error_llm = True\n",
                "    while error_llm:\n",
                "        try:\n",
                "            answer = send_prompt(instructions, prompt, temp=TEMPERATURE, max_tokens=1000)\n",
                "            error_llm = False\n",
                "        except Exception as err:\n",
                "            print(f\"Error encountered (message {i}/{num_real_messages}):\", err)\n",
                "            num_llm_errors += 1\n",
                "            error_llm = True\n",
                "            if num_llm_errors >= MAX_LLM_ERRORS:\n",
                "                print(\"Max Errors reached. Local break run\")\n",
                "                break\n",
                "    if num_llm_errors >= MAX_LLM_ERRORS:\n",
                "        print(\"Max Errors reached. Break run\")\n",
                "        break\n",
                "    correctness = correctness_percentage(answer)\n",
                "    while correctness >= 0.2:\n",
                "        print(\"Correction\")\n",
                "        correction_prompt = correctness_prompt(node_i.news, answer)\n",
                "        print(correction_prompt)\n",
                "        answer = send_prompt(instructions, correction_prompt, temp=TEMPERATURE, max_tokens=1000)\n",
                "        correctness = correctness_percentage(answer)\n",
                "    \n",
                "    node_i.set_message(answer)\n",
                "    list_prompts.append((node_i.name, prompt))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "164 / 163\n"
                    ]
                }
            ],
            "source": [
                "print(i, \"/\", num_real_messages)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Plot the Network in a Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "NEWS: Dictan prisión preventiva para Pablo Mackenna tras protagonizar accidente de tránsito en estado de ebriedad en Las Condes. \n",
                        "├── 43 (t=13:52)(herd)(0) repost\n",
                        "├── 40 (t=15:37)(wise)(0) repost\n",
                        "│   ├── 79 (t=18:42)(dumb)(2) repost\n",
                        "│   └── 88 (t=20:29)(herd)(2) repost\n",
                        "├── 15 (t=15:57)(wise)(0) repost\n",
                        "│   ├── 50 (t=18:27)(dumb)(3) repost\n",
                        "│   │   ├── 1 (t=19:54)(herd)(8) ''\n",
                        "│   │   │   └── 41 (t=20:05)(dumb)(19) ''\n",
                        "│   │   │       ├── 39 (t=20:42)(dumb)(20) ''\n",
                        "│   │   │       └── 82 (t=22:54)(dumb)(20) repost\n",
                        "│   │   └── 22 (t=22:41)(dumb)(8) repost\n",
                        "│   ├── 2 (t=20:37)(dumb)(3) repost\n",
                        "│   │   ├── 36 (t=21:23)(dumb)(25) ''\n",
                        "│   │   │   └── 27 (t=21:36)(herd)(34) repost\n",
                        "│   │   │       ├── 77 (t=21:48)(herd)(40) repost\n",
                        "│   │   │       └── 73 (t=22:35)(herd)(40) repost\n",
                        "│   │   └── 2 (t=22:11)(dumb)(25) ''\n",
                        "│   └── 11 (t=21:00)(herd)(3) repost\n",
                        "│       ├── 28 (t=21:13)(wise)(30) repost\n",
                        "│       │   └── 12 (t=22:58)(wise)(31) ''\n",
                        "│       ├── 4 (t=21:31)(dumb)(30) repost\n",
                        "│       ├── 9 (t=21:33)(dumb)(30) repost\n",
                        "│       │   └── 9 (t=22:19)(dumb)(38) ''\n",
                        "│       │       └── 99 (t=22:53)(dumb)(51) ''\n",
                        "│       ├── 68 (t=22:05)(dumb)(30) repost\n",
                        "│       ├── 19 (t=22:16)(dumb)(30) repost\n",
                        "│       ├── 37 (t=22:32)(dumb)(30) repost\n",
                        "│       └── 11 (t=22:38)(herd)(30) ''\n",
                        "├── 32 (t=17:34)(herd)(0) ''\n",
                        "│   ├── 63 (t=21:11)(wise)(4) repost\n",
                        "│   │   └── 60 (t=21:53)(herd)(32) repost\n",
                        "│   └── 32 (t=21:32)(herd)(4) ''\n",
                        "├── 48 (t=17:57)(herd)(0) repost\n",
                        "│   ├── 14 (t=18:12)(dumb)(5) ''\n",
                        "│   ├── 29 (t=19:45)(dumb)(5) ''\n",
                        "│   │   └── 94 (t=19:55)(dumb)(17) repost\n",
                        "│   │       ├── 10 (t=21:17)(herd)(18) repost\n",
                        "│   │       │   ├── 38 (t=22:37)(wise)(33) repost\n",
                        "│   │       │   └── 84 (t=22:49)(herd)(33) repost\n",
                        "│   │       ├── 76 (t=21:38)(herd)(18) repost\n",
                        "│   │       │   └── 76 (t=21:43)(herd)(41) ''\n",
                        "│   │       └── 94 (t=22:09)(dumb)(18) ''\n",
                        "│   ├── 96 (t=22:28)(herd)(5) repost\n",
                        "│   └── 80 (t=22:34)(wise)(5) repost\n",
                        "├── 24 (t=18:22)(herd)(0) repost\n",
                        "│   ├── 64 (t=19:32)(dumb)(7) repost\n",
                        "│   └── 24 (t=20:19)(herd)(7) ''\n",
                        "│       └── 0 (t=21:21)(herd)(23) repost\n",
                        "│           ├── 66 (t=21:44)(dumb)(36) repost\n",
                        "│           ├── 8 (t=22:13)(dumb)(36) repost\n",
                        "│           │   └── 31 (t=22:42)(herd)(50) repost\n",
                        "│           └── 44 (t=22:51)(wise)(36) ''\n",
                        "├── 49 (t=18:43)(herd)(0) repost\n",
                        "├── 55 (t=19:07)(dumb)(0) ''\n",
                        "│   └── 3 (t=19:41)(dumb)(11) repost\n",
                        "│       ├── 35 (t=19:48)(dumb)(15) ''\n",
                        "│       │   └── 51 (t=20:06)(wise)(16) repost\n",
                        "│       ├── 21 (t=20:18)(dumb)(15) repost\n",
                        "│       │   ├── 71 (t=20:44)(wise)(22) repost\n",
                        "│       │   │   └── 92 (t=22:23)(dumb)(27) repost\n",
                        "│       │   ├── 23 (t=21:23)(dumb)(22) repost\n",
                        "│       │   │   └── 6 (t=22:16)(herd)(35) ''\n",
                        "│       │   └── 25 (t=22:56)(herd)(22) repost\n",
                        "│       ├── 34 (t=21:57)(herd)(15) ''\n",
                        "│       └── 18 (t=22:56)(dumb)(15) repost\n",
                        "├── 13 (t=19:30)(wise)(0) repost\n",
                        "│   ├── 42 (t=19:40)(dumb)(12) repost\n",
                        "│   │   └── 42 (t=22:18)(dumb)(14) ''\n",
                        "│   ├── 90 (t=20:42)(wise)(12) repost\n",
                        "│   └── 98 (t=22:37)(dumb)(12) repost\n",
                        "├── 46 (t=20:42)(wise)(0) ''\n",
                        "│   └── 7 (t=22:36)(dumb)(29) repost\n",
                        "├── 43 (t=13:47)(herd)(0) repost\n",
                        "├── 40 (t=15:35)(wise)(0) repost\n",
                        "│   ├── 79 (t=18:47)(dumb)(2) repost\n",
                        "│   └── 88 (t=20:30)(herd)(2) repost\n",
                        "├── 15 (t=15:54)(wise)(0) repost\n",
                        "│   ├── 50 (t=18:32)(dumb)(3) repost\n",
                        "│   │   ├── 1 (t=19:54)(herd)(8) ''\n",
                        "│   │   │   └── 41 (t=20:06)(dumb)(19) ''\n",
                        "│   │   │       ├── 39 (t=20:43)(dumb)(20) ''\n",
                        "│   │   │       └── 82 (t=22:55)(dumb)(20) repost\n",
                        "│   │   └── 22 (t=22:43)(dumb)(8) repost\n",
                        "│   ├── 2 (t=20:36)(dumb)(3) repost\n",
                        "│   │   ├── 36 (t=21:21)(dumb)(25) ''\n",
                        "│   │   │   └── 27 (t=21:41)(herd)(34) repost\n",
                        "│   │   │       ├── 77 (t=21:44)(herd)(40) repost\n",
                        "│   │   │       └── 73 (t=22:33)(herd)(40) repost\n",
                        "│   │   └── 2 (t=22:10)(dumb)(25) ''\n",
                        "│   └── 11 (t=20:55)(herd)(3) repost\n",
                        "│       ├── 28 (t=21:12)(wise)(30) repost\n",
                        "│       │   └── 12 (t=22:54)(wise)(31) ''\n",
                        "│       ├── 4 (t=21:27)(dumb)(30) repost\n",
                        "│       ├── 9 (t=21:26)(dumb)(30) repost\n",
                        "│       │   └── 9 (t=22:17)(dumb)(38) ''\n",
                        "│       │       └── 99 (t=22:58)(dumb)(51) ''\n",
                        "│       ├── 68 (t=21:58)(dumb)(30) repost\n",
                        "│       ├── 19 (t=22:15)(dumb)(30) repost\n",
                        "│       ├── 37 (t=22:34)(dumb)(30) repost\n",
                        "│       └── 11 (t=22:39)(herd)(30) ''\n",
                        "├── 32 (t=17:33)(herd)(0) ''\n",
                        "│   ├── 63 (t=21:15)(wise)(4) repost\n",
                        "│   │   └── 60 (t=21:52)(herd)(32) repost\n",
                        "│   └── 32 (t=21:31)(herd)(4) ''\n",
                        "├── 48 (t=18:02)(herd)(0) repost\n",
                        "│   ├── 14 (t=18:18)(dumb)(5) ''\n",
                        "│   ├── 29 (t=19:49)(dumb)(5) ''\n",
                        "│   │   └── 94 (t=19:57)(dumb)(17) repost\n",
                        "│   │       ├── 10 (t=21:16)(herd)(18) repost\n",
                        "│   │       │   ├── 38 (t=22:38)(wise)(33) repost\n",
                        "│   │       │   └── 84 (t=22:46)(herd)(33) repost\n",
                        "│   │       ├── 76 (t=21:34)(herd)(18) repost\n",
                        "│   │       │   └── 76 (t=21:47)(herd)(41) ''\n",
                        "│   │       └── 94 (t=22:06)(dumb)(18) ''\n",
                        "│   ├── 96 (t=22:26)(herd)(5) repost\n",
                        "│   └── 80 (t=22:30)(wise)(5) repost\n",
                        "├── 24 (t=18:24)(herd)(0) repost\n",
                        "│   ├── 64 (t=19:32)(dumb)(7) repost\n",
                        "│   └── 24 (t=20:18)(herd)(7) ''\n",
                        "│       └── 0 (t=21:21)(herd)(23) repost\n",
                        "│           ├── 66 (t=21:43)(dumb)(36) repost\n",
                        "│           ├── 8 (t=22:15)(dumb)(36) repost\n",
                        "│           │   └── 31 (t=22:42)(herd)(50) repost\n",
                        "│           └── 44 (t=22:51)(wise)(36) ''\n",
                        "├── 49 (t=18:43)(herd)(0) repost\n",
                        "├── 55 (t=19:09)(dumb)(0) ''\n",
                        "│   └── 3 (t=19:41)(dumb)(11) repost\n",
                        "│       ├── 35 (t=19:51)(dumb)(15) ''\n",
                        "│       │   └── 51 (t=20:04)(wise)(16) repost\n",
                        "│       ├── 21 (t=20:18)(dumb)(15) repost\n",
                        "│       │   ├── 71 (t=20:42)(wise)(22) repost\n",
                        "│       │   │   └── 92 (t=22:22)(dumb)(27) repost\n",
                        "│       │   ├── 23 (t=21:19)(dumb)(22) repost\n",
                        "│       │   │   └── 6 (t=22:20)(herd)(35) ''\n",
                        "│       │   └── 25 (t=22:53)(herd)(22) repost\n",
                        "│       ├── 34 (t=21:51)(herd)(15) ''\n",
                        "│       └── 18 (t=22:52)(dumb)(15) repost\n",
                        "├── 13 (t=19:30)(wise)(0) repost\n",
                        "│   ├── 42 (t=19:37)(dumb)(12) repost\n",
                        "│   │   └── 42 (t=22:18)(dumb)(14) ''\n",
                        "│   ├── 90 (t=20:41)(wise)(12) repost\n",
                        "│   └── 98 (t=22:43)(dumb)(12) repost\n",
                        "└── 46 (t=20:40)(wise)(0) ''\n",
                        "    └── 7 (t=22:35)(dumb)(29) repost\n"
                    ]
                }
            ],
            "source": [
                "if SHOW_TREE:\n",
                "    for pre, _, node in RenderTree(root):\n",
                "        if node.name == 0:\n",
                "            print(f\"{pre}NEWS: {node.message}\")\n",
                "            continue\n",
                "\n",
                "        if node.repost:\n",
                "            message = \"repost\"\n",
                "        else:\n",
                "            message = \"'\"+node.message+\"'\"\n",
                "        print(f\"{pre}{node.owner} (t={node.step})({node.type_agent})({node.parent.name}) {message}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
